# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).

__all__ = ['TaskLabels', 'TypeDispatch2', 'DispatchReg2', 'typedispatch2', 'reduce_lbls', 'compose_tfms2', 'Pipeline2',
           'ABSTAIN']

# Cell
from fastai2.basics import *
from fastai2.text.all import Tokenizer

# Cell
# TODO: Implement show
class TaskLabels(TensorBase):
    def show(self, ctx=None, **kwargs): return str([categorize.decode(o) for o in self])

# Cell
class TypeDispatch2(TypeDispatch):
    def __call__(self, *args, **kwargs):
        res = super().__call__(*args, **kwargs)
        if res is args[0]: return None
        return res

# Cell
class DispatchReg2(DispatchReg):
    def __init__(self): self.d = defaultdict(TypeDispatch2)
typedispatch2 = DispatchReg2()

# Cell
def reduce_lbls(lbls):
    lbls = lbls.filter(partial(equals, None), negate=True) # Remove all Nones
    if len(lbls)>1: raise ValueError # TODO: Should figure out this case
    return lbls[0] if len(lbls)==1 else ABSTAIN # Can return None instead of abstain?

# Cell
def compose_tfms2(x, tfms, lfs, is_enc=True, reverse=False, **kwargs):
    "Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order"
    if reverse: tfms = reversed(tfms)
    lbls = L(L() for _ in range_of(lfs))
    for i,lf in enumerate(lfs): lbls[i].append(lf(x))
    for f in tfms:
        if not is_enc: f = f.decode
        x = f(x, **kwargs)
        for i,lf in enumerate(lfs): lbls[i].append(lf(x))
    # TODO: LF can be called twice (if types repeat)
    lbls = [reduce_lbls(v) for v in lbls]
    return lbls

# Cell
@delegates(Pipeline.__init__)
class Pipeline2(Pipeline):
    def __init__(self, funcs=None, lfs=None, **kwargs):
        super().__init__(funcs=funcs, **kwargs)
        self.lfs = lfs
    def __call__(self, o, **kwargs): return compose_tfms2(o, tfms=self.fs, lfs=self.lfs, split_idx=self.split_idx)
    def decode(self, o, full=True, split_idx=None):
        return super().decode(o, full=full)

# Cell
ABSTAIN = 'abstain'