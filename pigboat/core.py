# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).

__all__ = ['TypeDispatch2', 'DispatchReg2', 'typedispatch2', 'reduce_lbls', 'compose_tfms2', 'Pipeline2']

# Cell
from fastai2.basics import *

# Cell
class TypeDispatch2(TypeDispatch):
    def __call__(self, *args, **kwargs):
        res = super().__call__(*args, **kwargs)
        if res is args[0]: return None
        return res

# Cell
class DispatchReg2(DispatchReg):
    def __init__(self): self.d = defaultdict(TypeDispatch2)
typedispatch2 = DispatchReg2()

# Cell
def reduce_lbls(lbls):
    lbls = lbls.filter(partial(equals, None), negate=True) # Remove all Nones
    if len(lbls)>1: raise ValueError # TODO: Should figure out this case
    return lbls[0] if len(lbls)==1 else 'ABSTAIN'

# Cell
def compose_tfms2(x, tfms, lfs, is_enc=True, reverse=False, **kwargs):
    "Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order"
    if reverse: tfms = reversed(tfms)
    lbls = defaultdict(L)
    for i,lf in enumerate(lfs): lbls[i].append(lf(x))
    for f in tfms:
        if not is_enc: f = f.decode
        x = f(x, **kwargs)
        for i,lf in enumerate(lfs): lbls[i].append(lf(x))
    # TODO: LF can be called twice (if types repeat)
    lbls = {k:reduce_lbls(v) for k,v in lbls.items()} # This is how you reduce it
    return lbls

# Cell
@delegates(Pipeline.__init__)
class Pipeline2(Pipeline):
    def __init__(self, funcs=None, lfs=None, **kwargs):
        super().__init__(funcs=funcs, **kwargs)
        self.lfs = lfs
    def __call__(self, o): return compose_tfms2(o, tfms=self.fs, lfs=self.lfs, split_idx=self.split_idx)